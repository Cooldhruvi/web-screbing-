{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d262b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopean('hhtp://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.paser\")\n",
    "titles = bs.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "print('List all the headertags': *titles, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf845cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Downloading imbd top 100 movies's data\n",
    "url = 'http://www.imbd.com/chart/top'\n",
    "response = request.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titlecolumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titlecolumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "          for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "\n",
    "\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "\n",
    "for index in range(0, len(movies)):\n",
    "    \n",
    "    # Separating movies into: 'place',\n",
    "    # 'title', 'year'\n",
    "    \n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split ()).replaced('.',''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*)\\)' , movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\":place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": rating[index],\n",
    "            \"year\": year\n",
    "            \"star_cast\": crew[index]}\n",
    "    list.append(data)\n",
    "    \n",
    "    # printing movie details with its rating.\n",
    "    \n",
    "    for movie in list:\n",
    "        print(movie['place'],'-',movie['movie_title'],'('+movie['year']+') -','Starring:, movie['star_cast'], movie['rating'])\n",
    "              \n",
    " df = pd.DataFrame(list)\n",
    " df.to_csv('imbd_top_100_movies.csv',index=false)             \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://www.imbd.com/chart/top'\n",
    "responsr = requests.get(url)\n",
    "soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "movies = soup.select('td.titlecolumn')\n",
    "crew = [a,attrs.get('title') for a in soup.select('td.titlecolumn a')]\n",
    "rating = [b.attrs.get('data-value')\n",
    "          for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "list = []\n",
    "\n",
    "for index in range(0, len(movies)):\n",
    "    \n",
    "    movies_string = movies[index].get_text()\n",
    "    movie = (''.join(movie_string.split()).replaced('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\(.*)\\').movie_string).group(1)\n",
    "    place = movies[:len:len(str(index))-(len(movie))]\n",
    "    data = {\"place\":place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            \"star_cast\": crew[index]}\n",
    "   \n",
    "    list.append(data)\n",
    "                     \n",
    "for movie in list:\n",
    "    print(movie['place'], '-', movie['movie_title'], '('+movie['year']+') -', 'Starring:', movie['star_cast'], movie['rating'])\n",
    "                     \n",
    "df = pd.DataFrame(list)\n",
    "df.to_csv('imbd_top_100_movies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import reuest\n",
    "r = request.get('https://prsidentofindia.nic.in/former-presidents.html')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "results = soup.find_all('span', attrs={'class':'short-desc'})\n",
    "\n",
    "records = []\n",
    "for result in results:\n",
    "    date = result.find('strong').text[0:-1] + '2017'\n",
    "    lie = result.consent[1][1:-2]\n",
    "    explanation = result.find('a').text[1:-1]\n",
    "    url = result.find('a')['href']\n",
    "    records.append((date,lie,explanation,url))\n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(records,columns=['date','lie','explanation','url'])\n",
    "df[date] = pd.to_datetime(df['date'])\n",
    "df.to_csv('trump_lies.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data=soup.find(\"div\",attrs={\"data-criket-score\":\"odi\"}).find(\"div\",class_=\"rankings-block__top-players\").get_text(strip=True,separator=\" \").split(\" \")\n",
    "\n",
    "other_data=soup.find(\"div\",attrs={\"data-cricket-scope\":\"odi\"}).find_all(\"tr\",class_=\"table-body\")\n",
    "\n",
    "final_lst=[]\n",
    "final_lst.append(first_data)\n",
    "\n",
    "for i in data\n",
    "    split_lst=i.get_text(strip=True,separator=\" \").split(\" \")\n",
    "    final_lst.append(split_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url='http://.cnbc.com/world/region=world:'\n",
    "request = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "headline = soup.find('body').find_all('h3')\n",
    "for x in headlines:\n",
    "    print(x.text.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "frombs4 import BeautifulSoup\n",
    "\n",
    "url='dineout.co.in'\n",
    "soup = BeautifulSoup(conten,\"html.parser\")\n",
    "list_rest = []\n",
    "for tr in list_tr\n",
    "    dataframe={}\n",
    "    dataframe[\"Restaurant name\"]\n",
    "    dataframe[\"cuisine\"]\n",
    "    dataframe[\"Location\"]\n",
    "    dataframe[\"Ratings\"]\n",
    "    datahrame[\"Image URL\"]\n",
    "    list_rest.append(dataframe)\n",
    "list_rest\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(list_rest)\n",
    "df.to_csv(\"dineout.co.in\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
